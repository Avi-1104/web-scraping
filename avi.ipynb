{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff3736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e89fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a8646a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d450524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f931a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['APPLE iPhone 12 (Blue, 128 GB)', 'Nothing Phone (2) (Dark Grey, 512 GB)', 'SAMSUNG Galaxy Z Flip3 5G (Cream, 128 GB)', 'Google Pixel 7 (Lemongrass, 128 GB)', 'Google Pixel 7 (Snow, 128 GB)', 'Google Pixel 7 (Obsidian, 128 GB)', 'SAMSUNG Galaxy S22 5G (Phantom White, 128 GB)', 'SAMSUNG Galaxy A54 5G (Awesome Lime, 256 GB)', 'SAMSUNG Galaxy Z Flip3 5G (Phantom Black, 128 GB)', 'SAMSUNG Galaxy S22 5G (Green, 128 GB)', 'SAMSUNG Galaxy S22 5G (Phantom Black, 128 GB)', 'vivo V29 Pro 5G (Blue, 256 GB)', 'Nothing Phone (2) (White, 512 GB)', 'vivo V29 Pro 5G (Black, 256 GB)', 'OnePlus 10 Pro 5G (Emerald Forest, 128 GB)', 'OnePlus 10 Pro 5G (Emerald Forest, 128 GB)', 'APPLE iPhone 11 (White, 128 GB)', 'OnePlus 10T 5G (Moonstone Black, 256 GB)', 'OnePlus 10 Pro 5G (Volcanic Black, 128 GB)', 'OnePlus 10 Pro 5G (Volcanic Black, 128 GB)', 'APPLE iPhone 12 (Black, 128 GB)', 'Mi 10T Pro (Cosmic Black, 128 GB)', 'APPLE iPhone 12 (Red, 128 GB)', 'Tecno Phantom X2 Pro Retractable 50MP Portrait Lens (Mars Orange, 256 GB)']\n",
      "24\n",
      "[b'\\xe2\\x82\\xb948,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb945,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb937,499', b'\\xe2\\x82\\xb945,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb942,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb942,999', b'\\xe2\\x82\\xb945,970', b'\\xe2\\x82\\xb945,990', b'\\xe2\\x82\\xb948,900', b'\\xe2\\x82\\xb947,999', b'\\xe2\\x82\\xb942,887', b'\\xe2\\x82\\xb945,885', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb947,999', b'\\xe2\\x82\\xb949,999', b'\\xe2\\x82\\xb941,999']\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pandas\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "\n",
    "Product_name=[]\n",
    "Prices=[]\n",
    "Description=[]\n",
    "Reviews=[]\n",
    "# for i in range(2,10) :\n",
    "\n",
    "url=\"https://www.flipkart.com/search?q=mobile%20under%2050000&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(1)\n",
    "\n",
    "r=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(r.text,\"lxml\")\n",
    "\n",
    "names=soup.find_all(\"div\",class_=\"_4rR01T\")\n",
    "for i in names :\n",
    "    name=i.text\n",
    "    Product_name.append(name)\n",
    "\n",
    "print(Product_name)\n",
    "print(len(Product_name))\n",
    "\n",
    "prices=soup.find_all(\"div\",class_=\"_30jeq3 _1_WHN1\")\n",
    "for i in prices :\n",
    "    price=i.text.strip().encode(\"utf-8\")\n",
    "    Prices.append(price)\n",
    "print(Prices)\n",
    "print(len(Prices))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # np=soup.find(\"a\",class_=\"_1LKTO3\").get(\"href\")\n",
    "    # cnp=\"https://www.flipkart.com\"+np\n",
    "\n",
    "    # print(cnp)\n",
    "\n",
    "    # url=cnp\n",
    "    # r=requests.get(url)\n",
    "    # soup=BeautifulSoup(r.text,\"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e86f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Product Name, Prices, Description, Reviews]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Product_name = []\n",
    "Prices = []\n",
    "Description = []\n",
    "Reviews = []\n",
    "\n",
    "for i in range(1, 6):  # Adjust range based on the actual number of pages\n",
    "    try :\n",
    "        url = \"https://www.flipkart.com/search?q=mobile%20under%2050000&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(i)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "        boxes = soup.find_all(\"div\", class_=\"_1YokD2_3Mn1Gg\")\n",
    "        for box in boxes:\n",
    "            names = box.find_all(\"div\", class_=\"_4rR01T\")\n",
    "            for name in names:\n",
    "                Product_name.append(name.text)\n",
    "\n",
    "            prices = box.find_all(\"div\", class_=\"_30jeq3_1_WHN1\")\n",
    "            for price in prices:\n",
    "                Prices.append(price.text)\n",
    "\n",
    "            descs = box.find_all(\"ul\", class_=\"_1xgFaf\")\n",
    "            for desc in descs:\n",
    "                Description.append(desc.text)\n",
    "\n",
    "            reviews = box.find_all(\"div\", class_=\"_3LWZlK\")\n",
    "            for review in reviews:\n",
    "                Reviews.append(review.text)\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch page {i}: {e}\")\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "assert len(Product_name) == len(Prices) == len(Description) == len(Reviews)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Product Name\": Product_name,\n",
    "    \"Prices\": Prices,\n",
    "    \"Description\": Description,\n",
    "    \"Reviews\": Reviews\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c2995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Product Name, Prices, Description, Reviews]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Product_name = []\n",
    "Prices = []\n",
    "Description = []\n",
    "Reviews = []\n",
    "\n",
    "for i in range(1, 2):  # Testing on a single page first\n",
    "    try:\n",
    "        url = \"https://www.flipkart.com/search?q=mobile%20under%2050000&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(i)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        boxes = soup.find_all(\"div\", class_=\"_1YokD2_3Mn1Gg\")\n",
    "        for box in boxes:\n",
    "            names = box.find_all(\"div\", class_=\"_4rR01T\")\n",
    "            for name in names:\n",
    "                print(\"Name:\", name.text)\n",
    "                Product_name.append(name.text)\n",
    "\n",
    "            prices = box.find_all(\"div\", class_=\"_30jeq3_1_WHN1\")\n",
    "            for price in prices:\n",
    "                print(\"Price:\", price.text)\n",
    "                Prices.append(price.text)\n",
    "\n",
    "            descs = box.find_all(\"ul\", class_=\"_1xgFaf\")\n",
    "            for desc in descs:\n",
    "                print(\"Description:\", desc.text)\n",
    "                Description.append(desc.text)\n",
    "\n",
    "            reviews = box.find_all(\"div\", class_=\"_3LWZlK\")\n",
    "            for review in reviews:\n",
    "                print(\"Review:\", review.text)\n",
    "                Reviews.append(review.text)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch page {i}: {e}\")\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "assert len(Product_name) == len(Prices) == len(Description) == len(Reviews)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Product Name\": Product_name,\n",
    "    \"Prices\": Prices,\n",
    "    \"Description\": Description,\n",
    "    \"Reviews\": Reviews\n",
    "})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fbc545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "                                         Product Name   Prices Description  \\\n",
      "0               Nothing Phone (2) (Dark Grey, 512 GB)  ₹49,999               \n",
      "1                      APPLE iPhone 12 (Blue, 128 GB)  ₹48,999               \n",
      "2           SAMSUNG Galaxy Z Flip3 5G (Cream, 128 GB)  ₹45,999               \n",
      "3                      vivo V29 Pro 5G (Blue, 256 GB)  ₹42,999               \n",
      "4                   Nothing Phone (2) (White, 512 GB)  ₹49,999               \n",
      "5                       Google Pixel 7 (Snow, 128 GB)  ₹49,999               \n",
      "6                 Google Pixel 7 (Lemongrass, 128 GB)  ₹49,999               \n",
      "7                     vivo V29 Pro 5G (Black, 256 GB)  ₹42,999               \n",
      "8                   Google Pixel 7 (Obsidian, 128 GB)  ₹49,999               \n",
      "9       SAMSUNG Galaxy S22 5G (Phantom White, 128 GB)  ₹49,999               \n",
      "10  SAMSUNG Galaxy Z Flip3 5G (Phantom Black, 128 GB)  ₹45,999               \n",
      "11      SAMSUNG Galaxy S22 5G (Phantom Black, 128 GB)  ₹49,999               \n",
      "12              SAMSUNG Galaxy S22 5G (Green, 128 GB)  ₹49,999               \n",
      "13                    APPLE iPhone 12 (Black, 128 GB)  ₹49,999               \n",
      "14         OnePlus 10 Pro 5G (Volcanic Black, 128 GB)  ₹42,790               \n",
      "15         OnePlus 10 Pro 5G (Emerald Forest, 128 GB)  ₹45,970               \n",
      "16                    APPLE iPhone 11 (White, 128 GB)  ₹48,900               \n",
      "17         OnePlus 10 Pro 5G (Emerald Forest, 128 GB)  ₹45,990               \n",
      "18                    APPLE iPhone 11 (Black, 128 GB)  ₹48,900               \n",
      "19           OnePlus 10T 5G (Moonstone Black, 256 GB)  ₹47,999               \n",
      "20       Tecno Phantom X2 Pro (Stardust Grey, 256 GB)  ₹41,999               \n",
      "21  Tecno Phantom X2 Pro Retractable 50MP Portrait...  ₹41,999               \n",
      "22         OnePlus 10 Pro 5G (Volcanic Black, 128 GB)  ₹45,885               \n",
      "23                  Mi 10T Pro (Cosmic Black, 128 GB)  ₹47,999               \n",
      "\n",
      "   Reviews  \n",
      "0      4.4  \n",
      "1      4.6  \n",
      "2      4.3  \n",
      "3      4.5  \n",
      "4      4.4  \n",
      "5      4.3  \n",
      "6      4.3  \n",
      "7      4.5  \n",
      "8      4.3  \n",
      "9      4.4  \n",
      "10     4.3  \n",
      "11     4.4  \n",
      "12     4.4  \n",
      "13     4.6  \n",
      "14     4.2  \n",
      "15     4.2  \n",
      "16     4.6  \n",
      "17     4.2  \n",
      "18     4.6  \n",
      "19       4  \n",
      "20     4.1  \n",
      "21     4.1  \n",
      "22     4.2  \n",
      "23     4.2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Product_name = []\n",
    "Prices = []\n",
    "Description = []\n",
    "Reviews = []\n",
    "\n",
    "for i in range(1, 2):  # Testing on a single page first\n",
    "    try:\n",
    "        url = \"https://www.flipkart.com/search?q=mobile%20under%2050000&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(i)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        boxes = soup.find_all(\"div\", class_=\"_1AtVbE\")\n",
    "        for box in boxes:\n",
    "            name = box.find(\"div\", class_=\"_4rR01T\")\n",
    "            price = box.find(\"div\", class_=\"_30jeq3\")\n",
    "\n",
    "            if name and price:\n",
    "                Product_name.append(name.text)\n",
    "                Prices.append(price.text)\n",
    "\n",
    "                desc = box.find(\"ul\", class_=\"vFw0gD\")\n",
    "                Description.append(desc.text.strip() if desc else \"\")\n",
    "\n",
    "                review = box.find(\"div\", class_=\"_3LWZlK\")\n",
    "                Reviews.append(review.text.strip() if review else \"\")\n",
    "                print(\"Data Extracted Successfully.\")\n",
    "            else:\n",
    "                print(\"Skipping an item due to missing data.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch page {i}: {e}\")\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "assert len(Product_name) == len(Prices) == len(Description) == len(Reviews)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Product Name\": Product_name,\n",
    "    \"Prices\": Prices,\n",
    "    \"Description\": Description,\n",
    "    \"Reviews\": Reviews\n",
    "})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9588d111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Skipping an item due to missing data.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Data Extracted Successfully.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "Skipping an item due to missing data.\n",
      "                                    Product Name   Prices Description Reviews\n",
      "0          Nothing Phone (2) (Dark Grey, 512 GB)  ₹49,999                 4.4\n",
      "1                 APPLE iPhone 12 (Blue, 128 GB)  ₹48,999                 4.6\n",
      "2      SAMSUNG Galaxy Z Flip3 5G (Cream, 128 GB)  ₹45,999                 4.3\n",
      "3                 vivo V29 Pro 5G (Blue, 256 GB)  ₹42,999                 4.5\n",
      "4              Nothing Phone (2) (White, 512 GB)  ₹49,999                 4.4\n",
      "..                                           ...      ...         ...     ...\n",
      "114         vivo V27 Pro 5G (Magic Blue, 256 GB)  ₹39,999                 4.4\n",
      "115  SAMSUNG Galaxy S21 FE 5G (Graphite, 128 GB)  ₹39,999                 4.3\n",
      "116        vivo V27 Pro 5G (Noble Black, 128 GB)  ₹37,999                 4.4\n",
      "117                   IQOO 9T 5G (ALPHA, 128 GB)  ₹45,799                 4.1\n",
      "118                Mi 10T (Lunar Silver, 128 GB)  ₹42,999                 4.1\n",
      "\n",
      "[119 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Product_name = []\n",
    "Prices = []\n",
    "Description = []\n",
    "Reviews = []\n",
    "\n",
    "# Adjust the range based on the total number of pages\n",
    "for i in range(1, 6):  # Assuming 5 pages, you can adjust this number\n",
    "    try:\n",
    "        url = \"https://www.flipkart.com/search?q=mobile%20under%2050000&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\" + str(i)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        boxes = soup.find_all(\"div\", class_=\"_1AtVbE\")\n",
    "        for box in boxes:\n",
    "            name = box.find(\"div\", class_=\"_4rR01T\")\n",
    "            price = box.find(\"div\", class_=\"_30jeq3\")\n",
    "\n",
    "            if name and price:\n",
    "                Product_name.append(name.text)\n",
    "                Prices.append(price.text)\n",
    "\n",
    "                desc = box.find(\"ul\", class_=\"vFw0gD\")\n",
    "                Description.append(desc.text.strip() if desc else \"\")\n",
    "\n",
    "                review = box.find(\"div\", class_=\"_3LWZlK\")\n",
    "                Reviews.append(review.text.strip() if review else \"\")\n",
    "                print(\"Data Extracted Successfully.\")\n",
    "            else:\n",
    "                print(\"Skipping an item due to missing data.\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch page {i}: {e}\")\n",
    "\n",
    "# Ensure all lists have the same length\n",
    "assert len(Product_name) == len(Prices) == len(Description) == len(Reviews)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Product Name\": Product_name,\n",
    "    \"Prices\": Prices,\n",
    "    \"Description\": Description,\n",
    "    \"Reviews\": Reviews\n",
    "})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2153466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
